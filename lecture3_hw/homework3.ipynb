{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "作業檔案：\n",
    "- hw3.ipynb\n",
    "\n",
    "資料：\n",
    "https://www.sharecast.com/index/SP_500/prices/download\n",
    "\n",
    "- train.csv: S&P 500 訓練資料(2009-2017)\n",
    "- test.csv: S&P 500 測試資料(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "drop_col_names = ['Date'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with the previous days as the training target\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   High Price  Low Price        Volume  Tomorrow Movement  Open Close Diff  \\\n",
      "0      934.73     899.35  4.048270e+09                0.0           -28.81   \n",
      "1      936.63     919.53  5.413910e+09                1.0             1.72   \n",
      "2      943.85     927.28  5.392620e+09                0.0            -3.53   \n",
      "3      927.45     902.37  4.704940e+09                1.0            20.80   \n",
      "4      910.00     896.81  4.991550e+09                0.0            -4.00   \n",
      "\n",
      "   High Low Diff  \n",
      "0          35.38  \n",
      "1          17.10  \n",
      "2          16.57  \n",
      "3          25.08  \n",
      "4          13.19  \n",
      "   High Price  Low Price        Volume  Tomorrow Movement  Open Close Diff  \\\n",
      "0     2695.89    2682.36  1.846463e+09                1.0           -12.08   \n",
      "1     2714.37    2697.77  2.090595e+09                1.0           -15.21   \n",
      "2     2729.29    2719.07  2.100768e+09                1.0            -4.68   \n",
      "3     2743.45    2727.92  1.918869e+09                1.0           -11.82   \n",
      "4     2748.51    2737.60  1.894824e+09                1.0            -5.04   \n",
      "\n",
      "   High Low Diff  \n",
      "0          13.53  \n",
      "1          16.60  \n",
      "2          10.22  \n",
      "3          15.53  \n",
      "4          10.91  \n"
     ]
    }
   ],
   "source": [
    "# !--- You can add your own data preprocessing here ---!\n",
    "train_df['Open Close Diff'] = train_df['Open Price'] - train_df['Close Price']\n",
    "test_df['Open Close Diff'] = test_df['Open Price'] - test_df['Close Price']\n",
    "\n",
    "train_df['High Low Diff'] = train_df['High Price'] - train_df['Low Price']\n",
    "test_df['High Low Diff'] = test_df['High Price'] - test_df['Low Price']\n",
    "# Drop unnecessary columns ,'High Price','Low Price'\n",
    "drop_col_names = ['Open Price','Close Price'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "# Convert np.int64 datatype into np.float64 type for later use\n",
    "train_df = train_df.astype(np.float64)\n",
    "test_df = test_df.astype(np.float64)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Movement</th>\n",
       "      <th>Open Close Diff</th>\n",
       "      <th>High Low Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4.048270e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-28.81</td>\n",
       "      <td>35.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5.413910e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5.392620e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.53</td>\n",
       "      <td>16.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4.704940e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.80</td>\n",
       "      <td>25.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4.991550e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>13.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   High Price  Low Price        Volume  Tomorrow Movement  Open Close Diff  \\\n",
       "0      934.73     899.35  4.048270e+09                0.0           -28.81   \n",
       "1      936.63     919.53  5.413910e+09                1.0             1.72   \n",
       "2      943.85     927.28  5.392620e+09                0.0            -3.53   \n",
       "3      927.45     902.37  4.704940e+09                1.0            20.80   \n",
       "4      910.00     896.81  4.991550e+09                0.0            -4.00   \n",
       "\n",
       "   High Low Diff  \n",
       "0          35.38  \n",
       "1          17.10  \n",
       "2          16.57  \n",
       "3          25.08  \n",
       "4          13.19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Movement</th>\n",
       "      <th>Open Close Diff</th>\n",
       "      <th>High Low Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2685.35</td>\n",
       "      <td>2678.13</td>\n",
       "      <td>1.383889e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>2682.74</td>\n",
       "      <td>2677.96</td>\n",
       "      <td>1.103808e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2685.64</td>\n",
       "      <td>2678.91</td>\n",
       "      <td>1.149108e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>6.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>2687.66</td>\n",
       "      <td>2682.69</td>\n",
       "      <td>1.126090e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>2692.12</td>\n",
       "      <td>2673.61</td>\n",
       "      <td>1.332374e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.54</td>\n",
       "      <td>18.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      High Price  Low Price        Volume  Tomorrow Movement  Open Close Diff  \\\n",
       "2259     2685.35    2678.13  1.383889e+09                0.0             0.88   \n",
       "2260     2682.74    2677.96  1.103808e+09                1.0            -1.41   \n",
       "2261     2685.64    2678.91  1.149108e+09                1.0            -0.52   \n",
       "2262     2687.66    2682.69  1.126090e+09                0.0            -1.44   \n",
       "2263     2692.12    2673.61  1.332374e+09                NaN            15.54   \n",
       "\n",
       "      High Low Diff  \n",
       "2259           7.22  \n",
       "2260           4.78  \n",
       "2261           6.73  \n",
       "2262           4.97  \n",
       "2263          18.51  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 5)\n",
      "   High Price  Low Price        Volume  Open Close Diff  High Low Diff\n",
      "0      934.73     899.35  4.048270e+09           -28.81          35.38\n",
      "1      936.63     919.53  5.413910e+09             1.72          17.10\n",
      "2      943.85     927.28  5.392620e+09            -3.53          16.57\n",
      "3      927.45     902.37  4.704940e+09            20.80          25.08\n",
      "4      910.00     896.81  4.991550e+09            -4.00          13.19\n",
      "(2263,)\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(251, 5)\n",
      "   High Price  Low Price        Volume  Open Close Diff  High Low Diff\n",
      "0     2695.89    2682.36  1.846463e+09           -12.08          13.53\n",
      "1     2714.37    2697.77  2.090595e+09           -15.21          16.60\n",
      "2     2729.29    2719.07  2.100768e+09            -4.68          10.22\n",
      "3     2743.45    2727.92  1.918869e+09           -11.82          15.53\n",
      "4     2748.51    2737.60  1.894824e+09            -5.04          10.91\n",
      "(251,)\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "train_x_df = train_df.drop(columns=['Tomorrow Movement'])\n",
    "train_y_df = train_df['Tomorrow Movement']\n",
    "\n",
    "test_x_df = test_df.drop(columns=['Tomorrow Movement'])\n",
    "test_y_df = test_df['Tomorrow Movement']\n",
    "\n",
    "print(train_x_df.shape)\n",
    "print(train_x_df.head())\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())\n",
    "print('-----')\n",
    "print(test_x_df.shape)\n",
    "print(test_x_df.head())\n",
    "print(test_y_df.shape)\n",
    "print(test_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   High Price  Low Price    Volume  Open Close Diff  High Low Diff\n",
      "0   -1.505683  -1.541181  0.813175        -2.089188       1.859140\n",
      "1   -1.501760  -1.499581  1.823826         0.174385       0.009988\n",
      "2   -1.486853  -1.483605  1.808070        -0.214864      -0.043625\n",
      "3   -1.520714  -1.534956  1.299148         1.589025       0.817222\n",
      "4   -1.556744  -1.546417  1.511255        -0.249711      -0.385536\n",
      "------\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "# !--- Modify here if you want ---!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_df)\n",
    "\n",
    "normalized_train_x_df = scaler.transform(train_x_df)\n",
    "normalized_train_x_df = np.transpose(normalized_train_x_df)\n",
    "normalized_train_x_df = pd.DataFrame({\n",
    "    'High Price': normalized_train_x_df[0],\n",
    "    'Low Price': normalized_train_x_df[1],\n",
    "    'Volume': normalized_train_x_df[2],\n",
    "    'Open Close Diff':normalized_train_x_df[3],\n",
    "    'High Low Diff':normalized_train_x_df[4]\n",
    "})\n",
    "\n",
    "normalized_test_x_df = scaler.transform(test_x_df)\n",
    "normalized_test_x_df = np.transpose(normalized_test_x_df)\n",
    "normalized_test_x_df = pd.DataFrame({\n",
    "    'High Price': normalized_test_x_df[0],\n",
    "    'Low Price': normalized_test_x_df[1],\n",
    "    'Volume': normalized_test_x_df[2],\n",
    "    #'Open Price Diff':normalized_test_x_df[3],\n",
    "    #'Close Price Diff':normalized_test_x_df[4],\n",
    "    'Open Close Diff':normalized_test_x_df[3],\n",
    "    'High Low Diff':normalized_test_x_df[4]\n",
    "})\n",
    "\n",
    "print(normalized_train_x_df.head())\n",
    "print('------')\n",
    "print(train_y_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if two classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1024 1239]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(train_y_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "\n",
    "#### Solver of sklearn logistic regression\n",
    "Algorithm to use in the optimization problem.\n",
    "\n",
    "*    For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "*    For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "*    ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "*    ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "*    ‘saga’ also supports ‘elasticnet’ penalty\n",
    "*    ‘liblinear’ does not handle no penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5457357490057446\n",
      "\n",
      "testing accuracy:\n",
      "0.47808764940239046\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict using Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression(penalty = \"l2\",solver='liblinear') # !--- Initialize the model here ---!\n",
    "lr_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "lr_training_acc = lr_model.score(normalized_train_x_df, train_y_df)\n",
    "print(lr_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "lr_predict_test_result = lr_model.predict(normalized_test_x_df)\n",
    "lr_testing_acc = np.mean(lr_predict_test_result == test_y_df)\n",
    "print(lr_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.4569589289899227, 0.47808764940239046, 0.44465064182688885, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(26, 93, 38, 94)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, lr_predict_test_result, average='weighted',labels=np.unique( lr_predict_test_result)))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, lr_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5612019443216969\n",
      "\n",
      "testing accuracy:\n",
      "0.4940239043824701\n",
      "\n",
      "predicted testing labels:\n",
      "[0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict with SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel = 'rbf',gamma=\"scale\") # !--- Initialize the model here ---!\n",
    "svc_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "svc_training_acc = svc_model.score(normalized_train_x_df, train_y_df)\n",
    "print(svc_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "svc_predict_test_result = svc_model.predict(normalized_test_x_df)\n",
    "svc_testing_acc = np.mean(svc_predict_test_result == test_y_df)\n",
    "print(svc_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(svc_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.48651573294107453, 0.4940239043824701, 0.4827219901202527, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(40, 79, 48, 84)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, svc_predict_test_result, average='weighted',labels=np.unique(svc_predict_test_result)))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, svc_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of data y indicate if it belongs to class '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 2)\n",
      "   0    1\n",
      "0  1  0.0\n",
      "1  0  1.0\n",
      "2  1  0.0\n",
      "3  0  1.0\n",
      "4  1  0.0\n"
     ]
    }
   ],
   "source": [
    "# Define NN output groundtruth\n",
    "falling_prob = pd.DataFrame(data=np.where(train_y_df == 0, 1, 0)[:])\n",
    "train_y_df_NN = pd.DataFrame(data=np.where(train_y_df == 0, 0, 1)[:],dtype = 'float64')\n",
    "train_y_df_NN = pd.concat( [ falling_prob, train_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(test_y_df == 0, 1, 0)[:])\n",
    "test_y_df_NN = pd.DataFrame(data=np.where(test_y_df == 0, 0, 1)[:],dtype = 'float64')\n",
    "test_y_df_NN = pd.concat( [ falling_prob, test_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "print(train_y_df_NN.shape)\n",
    "print(train_y_df_NN.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - loss:0.6924398541\n",
      "epoch:10 - loss:0.6878230572\n",
      "epoch:20 - loss:0.6865900755\n",
      "epoch:30 - loss:0.6859292388\n",
      "epoch:40 - loss:0.6854249835\n",
      "epoch:50 - loss:0.6849981546\n",
      "epoch:60 - loss:0.6846331954\n",
      "epoch:70 - loss:0.6843149066\n",
      "epoch:80 - loss:0.6840568781\n",
      "epoch:90 - loss:0.6837962270\n",
      "epoch:100 - loss:0.6835889816\n",
      "epoch:110 - loss:0.6834005713\n",
      "epoch:120 - loss:0.6832458973\n",
      "epoch:130 - loss:0.6830947399\n",
      "epoch:140 - loss:0.6829527617\n",
      "epoch:150 - loss:0.6828184128\n",
      "epoch:160 - loss:0.6826528311\n",
      "epoch:170 - loss:0.6824895740\n",
      "epoch:180 - loss:0.6823453903\n",
      "epoch:190 - loss:0.6821848750\n",
      "epoch:200 - loss:0.6820399165\n",
      "epoch:210 - loss:0.6818971038\n",
      "epoch:220 - loss:0.6817593575\n",
      "epoch:230 - loss:0.6816378236\n",
      "epoch:240 - loss:0.6815357804\n",
      "epoch:250 - loss:0.6814280152\n",
      "epoch:260 - loss:0.6813576818\n",
      "epoch:270 - loss:0.6812984943\n",
      "epoch:280 - loss:0.6811322570\n",
      "epoch:290 - loss:0.6809663177\n",
      "epoch:300 - loss:0.6808446050\n",
      "epoch:310 - loss:0.6807208657\n",
      "epoch:320 - loss:0.6806260943\n",
      "epoch:330 - loss:0.6805658937\n",
      "epoch:340 - loss:0.6804420948\n",
      "epoch:350 - loss:0.6803010106\n",
      "epoch:360 - loss:0.6801725626\n",
      "epoch:370 - loss:0.6800323725\n",
      "epoch:380 - loss:0.6798962951\n",
      "epoch:390 - loss:0.6797721982\n",
      "epoch:400 - loss:0.6796646714\n",
      "epoch:410 - loss:0.6795729399\n",
      "epoch:420 - loss:0.6794780493\n",
      "epoch:430 - loss:0.6794025302\n",
      "epoch:440 - loss:0.6793107986\n",
      "epoch:450 - loss:0.6792095304\n",
      "epoch:460 - loss:0.6791200638\n",
      "epoch:470 - loss:0.6790401340\n",
      "epoch:480 - loss:0.6789587736\n",
      "epoch:490 - loss:0.6788870096\n",
      "epoch:500 - loss:0.6788216233\n",
      "epoch:510 - loss:0.6787604690\n",
      "epoch:520 - loss:0.6787047386\n",
      "epoch:530 - loss:0.6786286235\n",
      "epoch:540 - loss:0.6785618663\n",
      "epoch:550 - loss:0.6785093546\n",
      "epoch:560 - loss:0.6784472466\n",
      "epoch:570 - loss:0.6783843637\n",
      "epoch:580 - loss:0.6783181429\n",
      "epoch:590 - loss:0.6782638431\n",
      "epoch:600 - loss:0.6782212257\n",
      "epoch:610 - loss:0.6781840324\n",
      "epoch:620 - loss:0.6781235337\n",
      "epoch:630 - loss:0.6780629158\n",
      "epoch:640 - loss:0.6780096292\n",
      "epoch:650 - loss:0.6779571772\n",
      "epoch:660 - loss:0.6778988242\n",
      "epoch:670 - loss:0.6778395176\n",
      "epoch:680 - loss:0.6777859926\n",
      "epoch:690 - loss:0.6777392030\n",
      "epoch:700 - loss:0.6776973009\n",
      "epoch:710 - loss:0.6776668429\n",
      "epoch:720 - loss:0.6776412129\n",
      "epoch:730 - loss:0.6776114702\n",
      "epoch:740 - loss:0.6775735021\n",
      "epoch:750 - loss:0.6775358915\n",
      "epoch:760 - loss:0.6774992943\n",
      "epoch:770 - loss:0.6774625778\n",
      "epoch:780 - loss:0.6774311066\n",
      "epoch:790 - loss:0.6774076819\n",
      "epoch:800 - loss:0.6773640513\n",
      "epoch:810 - loss:0.6773198843\n",
      "epoch:820 - loss:0.6772748828\n",
      "epoch:830 - loss:0.6772317290\n",
      "epoch:840 - loss:0.6771895885\n",
      "epoch:850 - loss:0.6771497130\n",
      "epoch:860 - loss:0.6771111488\n",
      "epoch:870 - loss:0.6770739555\n",
      "epoch:880 - loss:0.6770331264\n",
      "epoch:890 - loss:0.6769947410\n",
      "epoch:900 - loss:0.6769586205\n",
      "epoch:910 - loss:0.6769239306\n",
      "epoch:920 - loss:0.6768888235\n",
      "epoch:930 - loss:0.6768496633\n",
      "epoch:940 - loss:0.6768127084\n",
      "epoch:950 - loss:0.6767765284\n",
      "epoch:960 - loss:0.6767443419\n",
      "epoch:970 - loss:0.6767080426\n",
      "epoch:980 - loss:0.6766741872\n",
      "epoch:990 - loss:0.6766434908\n"
     ]
    }
   ],
   "source": [
    "# Define NN structure\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !--- You can modify the NN structure here ---!\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        self.linear3 = torch.nn.Linear(H, H)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input layer\n",
    "        i = self.linear1(x)\n",
    "        act_out = F.relu(i)\n",
    "        # Hidden layer\n",
    "        h1 = self.linear3(act_out)\n",
    "        act2_out = F.relu(h1)\n",
    "        # Output layer\n",
    "        o = self.linear2(act2_out)\n",
    "        y_pred = F.relu(o)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "# N = batch size, D_in = input size, H = hidden size, D_out = output size\n",
    "N, D_in, H, D_out = 250, 5, 100, 2  # !--- You can modify here ---!\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean') # !--- You can modify here ---!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3e-2) # !--- You can modify here ---!\n",
    "\n",
    "# Train NN\n",
    "# !--- You can modify here ---!\n",
    "\n",
    "for t in range(1000):\n",
    "    for batch_num in range(N, len(normalized_train_x_df), N): \n",
    "        data = torch.tensor(normalized_train_x_df.iloc[batch_num-N:batch_num].values) # !-- Transfer data into tensor form --!\n",
    "        y_pred = model(data.float()) # !-- Fill the training batch data here --!\n",
    "        target = torch.tensor(train_y_df_NN.iloc[batch_num-N:batch_num].values) # !-- Transfer target into tensor form --!\n",
    "        loss = criterion(y_pred,target.float()) # !-- Fill the prediction & groundtruth here to calculate loss --!\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%10 == 0):\n",
    "        print('epoch:%d - loss:%.10f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5501546619531595\n",
      "\n",
      "testing accuracy:\n",
      "0.46215139442231074\n",
      "\n",
      "predicted testing prob:\n",
      "tensor([[0.0614, 0.0000],\n",
      "        [0.1299, 0.0000],\n",
      "        [0.0044, 0.4661],\n",
      "        [0.0903, 0.0000],\n",
      "        [0.0048, 0.4052],\n",
      "        [0.0000, 0.6237],\n",
      "        [0.0289, 0.4503],\n",
      "        [0.1131, 0.0000],\n",
      "        [0.1647, 0.0000],\n",
      "        [0.1611, 0.5569],\n",
      "        [0.2789, 0.0000],\n",
      "        [0.0000, 0.8337],\n",
      "        [0.0680, 0.3932],\n",
      "        [0.2674, 0.0000],\n",
      "        [0.0330, 0.5542],\n",
      "        [0.1504, 0.5245],\n",
      "        [0.0316, 0.8236],\n",
      "        [0.2931, 0.0000],\n",
      "        [0.0013, 0.9308],\n",
      "        [0.0285, 0.8604],\n",
      "        [0.1330, 0.6345],\n",
      "        [0.1729, 0.1829],\n",
      "        [0.1239, 0.6401],\n",
      "        [0.2715, 0.9226],\n",
      "        [0.1447, 0.0000],\n",
      "        [0.3085, 0.2320],\n",
      "        [0.1981, 0.7032],\n",
      "        [0.1788, 0.6419],\n",
      "        [0.3000, 0.0000],\n",
      "        [0.2389, 0.0000],\n",
      "        [0.2633, 0.0000],\n",
      "        [0.3125, 0.0000],\n",
      "        [0.2135, 0.0127],\n",
      "        [0.1622, 0.3505],\n",
      "        [0.2277, 0.4026],\n",
      "        [0.1880, 0.2999],\n",
      "        [0.2693, 0.0000],\n",
      "        [0.2609, 0.0000],\n",
      "        [0.1239, 0.5912],\n",
      "        [0.1366, 0.5793],\n",
      "        [0.2701, 0.4848],\n",
      "        [0.2898, 0.0000],\n",
      "        [0.2936, 0.0000],\n",
      "        [0.0568, 0.4283],\n",
      "        [0.2444, 0.0000],\n",
      "        [0.0663, 0.1804],\n",
      "        [0.2883, 0.0000],\n",
      "        [0.0107, 0.7647],\n",
      "        [0.1621, 0.5532],\n",
      "        [0.0556, 0.6765],\n",
      "        [0.0382, 0.5857],\n",
      "        [0.0423, 0.8158],\n",
      "        [0.1703, 0.5076],\n",
      "        [0.0119, 0.4782],\n",
      "        [0.1637, 0.2537],\n",
      "        [0.1203, 0.5535],\n",
      "        [0.1639, 0.5554],\n",
      "        [0.2602, 0.0000],\n",
      "        [0.1918, 0.5953],\n",
      "        [0.2465, 0.2095],\n",
      "        [0.2846, 0.0000],\n",
      "        [0.1829, 0.6061],\n",
      "        [0.2668, 0.0000],\n",
      "        [0.2202, 0.0000],\n",
      "        [0.1000, 0.0678],\n",
      "        [0.1949, 0.4901],\n",
      "        [0.2406, 0.1607],\n",
      "        [0.2343, 0.0000],\n",
      "        [0.0393, 0.2941],\n",
      "        [0.1162, 0.0000],\n",
      "        [0.0847, 0.5459],\n",
      "        [0.0962, 0.0000],\n",
      "        [0.1592, 0.0000],\n",
      "        [0.0000, 0.6017],\n",
      "        [0.0245, 0.6383],\n",
      "        [0.0697, 0.6070],\n",
      "        [0.0666, 0.3748],\n",
      "        [0.1973, 0.5211],\n",
      "        [0.2112, 0.0000],\n",
      "        [0.2435, 0.0000],\n",
      "        [0.0031, 0.6019],\n",
      "        [0.0484, 0.6150],\n",
      "        [0.2129, 0.0000],\n",
      "        [0.0439, 0.6304],\n",
      "        [0.2807, 0.0204],\n",
      "        [0.2680, 0.0000],\n",
      "        [0.0375, 0.2329],\n",
      "        [0.0700, 0.2472],\n",
      "        [0.2327, 0.0000],\n",
      "        [0.1834, 0.0000],\n",
      "        [0.0233, 0.2501],\n",
      "        [0.0000, 0.5592],\n",
      "        [0.0000, 0.7004],\n",
      "        [0.0611, 0.0349],\n",
      "        [0.0558, 0.3204],\n",
      "        [0.0000, 0.7910],\n",
      "        [0.0303, 0.2304],\n",
      "        [0.0000, 0.7976],\n",
      "        [0.2240, 0.0000],\n",
      "        [0.0887, 0.3442],\n",
      "        [0.0000, 0.5961],\n",
      "        [0.1359, 0.4864],\n",
      "        [0.2395, 0.0000],\n",
      "        [0.0100, 0.8771],\n",
      "        [0.1438, 0.0000],\n",
      "        [0.0000, 0.4423],\n",
      "        [0.0000, 0.5564],\n",
      "        [0.2332, 0.0000],\n",
      "        [0.0429, 0.5825],\n",
      "        [0.0962, 0.0000],\n",
      "        [0.0000, 0.5718],\n",
      "        [0.0000, 0.5912],\n",
      "        [0.0000, 0.9453],\n",
      "        [0.0000, 0.6834],\n",
      "        [0.1526, 0.5183],\n",
      "        [0.0865, 0.1233],\n",
      "        [0.1565, 0.0000],\n",
      "        [0.0000, 0.7778],\n",
      "        [0.0065, 0.8145],\n",
      "        [0.0000, 0.9992],\n",
      "        [0.1738, 0.5003],\n",
      "        [0.0449, 0.4521],\n",
      "        [0.1730, 0.5095],\n",
      "        [0.2616, 0.0000],\n",
      "        [0.0772, 0.5519],\n",
      "        [0.2293, 0.0000],\n",
      "        [0.0000, 0.6477],\n",
      "        [0.1445, 0.0000],\n",
      "        [0.2398, 0.0000],\n",
      "        [0.1186, 0.0000],\n",
      "        [0.0000, 0.4163],\n",
      "        [0.0000, 0.7211],\n",
      "        [0.1405, 0.0000],\n",
      "        [0.0167, 0.3922],\n",
      "        [0.0000, 0.7440],\n",
      "        [0.2429, 0.0000],\n",
      "        [0.0133, 0.4905],\n",
      "        [0.0000, 0.8542],\n",
      "        [0.0000, 0.8192],\n",
      "        [0.0476, 0.2419],\n",
      "        [0.0712, 0.5005],\n",
      "        [0.3004, 0.0000],\n",
      "        [0.0173, 0.7186],\n",
      "        [0.1021, 0.6675],\n",
      "        [0.0208, 0.8203],\n",
      "        [0.1009, 0.3282],\n",
      "        [0.0395, 0.7315],\n",
      "        [0.2923, 0.0000],\n",
      "        [0.0690, 0.1401],\n",
      "        [0.0950, 0.0567],\n",
      "        [0.0000, 0.6353],\n",
      "        [0.0000, 0.6307],\n",
      "        [0.0000, 0.7823],\n",
      "        [0.0000, 0.7345],\n",
      "        [0.0233, 0.7342],\n",
      "        [0.1010, 0.0000],\n",
      "        [0.0863, 0.6125],\n",
      "        [0.1205, 0.0841],\n",
      "        [0.1678, 0.0000],\n",
      "        [0.0000, 0.5526],\n",
      "        [0.0092, 0.6006],\n",
      "        [0.0000, 0.5787],\n",
      "        [0.0000, 0.6453],\n",
      "        [0.0738, 0.0193],\n",
      "        [0.0895, 0.0969],\n",
      "        [0.0000, 0.8035],\n",
      "        [0.1344, 0.0000],\n",
      "        [0.0046, 0.7730],\n",
      "        [0.0402, 0.4746],\n",
      "        [0.0302, 0.6069],\n",
      "        [0.0464, 0.6741],\n",
      "        [0.0699, 0.6766],\n",
      "        [0.0857, 0.3163],\n",
      "        [0.0000, 0.7989],\n",
      "        [0.2411, 0.0000],\n",
      "        [0.0403, 0.5703],\n",
      "        [0.0404, 0.4296],\n",
      "        [0.0000, 0.6954],\n",
      "        [0.0000, 0.9129],\n",
      "        [0.1755, 0.0000],\n",
      "        [0.0000, 0.7174],\n",
      "        [0.1190, 0.1802],\n",
      "        [0.0267, 1.2067],\n",
      "        [0.0000, 0.8469],\n",
      "        [0.0000, 0.9770],\n",
      "        [0.1137, 0.6257],\n",
      "        [0.0674, 0.4271],\n",
      "        [0.0490, 0.5504],\n",
      "        [0.0796, 0.5923],\n",
      "        [0.0131, 0.7310],\n",
      "        [0.0466, 0.7566],\n",
      "        [0.1671, 0.5913],\n",
      "        [0.2167, 0.4922],\n",
      "        [0.2098, 0.0179],\n",
      "        [0.0863, 0.5422],\n",
      "        [0.1922, 0.7035],\n",
      "        [0.2936, 0.6096],\n",
      "        [0.3327, 0.1249],\n",
      "        [0.0577, 0.6154],\n",
      "        [0.3179, 0.0000],\n",
      "        [0.2312, 0.1893],\n",
      "        [0.1922, 0.5402],\n",
      "        [0.2510, 0.2993],\n",
      "        [0.0642, 0.6598],\n",
      "        [0.3155, 0.0475],\n",
      "        [0.1964, 0.6801],\n",
      "        [0.3016, 0.0000],\n",
      "        [0.3259, 0.2532],\n",
      "        [0.2379, 0.6759],\n",
      "        [0.2343, 0.0000],\n",
      "        [0.2613, 0.0203],\n",
      "        [0.2846, 0.0000],\n",
      "        [0.3052, 0.3477],\n",
      "        [0.2127, 0.0000],\n",
      "        [0.1729, 0.0000],\n",
      "        [0.3085, 0.0000],\n",
      "        [0.0798, 0.4320],\n",
      "        [0.1188, 0.5738],\n",
      "        [0.1316, 0.5829],\n",
      "        [0.2601, 0.2677],\n",
      "        [0.2451, 0.4670],\n",
      "        [0.2840, 0.0000],\n",
      "        [0.2944, 0.0000],\n",
      "        [0.1560, 0.5450],\n",
      "        [0.2170, 0.3373],\n",
      "        [0.0071, 0.5740],\n",
      "        [0.0000, 0.2534],\n",
      "        [0.2241, 0.0000],\n",
      "        [0.2233, 0.0000],\n",
      "        [0.2673, 0.0000],\n",
      "        [0.1927, 0.1174],\n",
      "        [0.2710, 0.0000],\n",
      "        [0.1819, 0.2833],\n",
      "        [0.1939, 0.6759],\n",
      "        [0.1973, 0.6766],\n",
      "        [0.2539, 0.0917],\n",
      "        [0.2027, 0.6390],\n",
      "        [0.2652, 0.2356],\n",
      "        [0.2107, 0.4197],\n",
      "        [0.2116, 0.2828],\n",
      "        [0.1755, 0.3292],\n",
      "        [0.1038, 0.5198],\n",
      "        [0.1906, 0.5292],\n",
      "        [0.2345, 0.2757],\n",
      "        [0.2099, 0.6378],\n",
      "        [0.2269, 0.4212],\n",
      "        [0.2934, 0.5881],\n",
      "        [0.0139, 0.4432],\n",
      "        [0.0973, 0.0429],\n",
      "        [0.1423, 0.3070],\n",
      "        [0.2057, 0.2612]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "predicted testing labels:\n",
      "[0 0 1 0 1 1 1 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0\n",
      " 0 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1\n",
      " 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0\n",
      " 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 0\n",
      " 0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "x_train = torch.tensor(normalized_train_x_df.values).float()\n",
    "nn_predict_train_y = model(x_train) # !-- Predict training data here --!\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 0, 1) # !-- You can modify here --!\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(train_y_df, result_train))\n",
    "\n",
    "x_test = torch.tensor(normalized_test_x_df.values).float()\n",
    "nn_predict_test_y = model(x_test) # !-- Predict training data here --!\n",
    "result_test = np.where(nn_predict_test_y[:, 0] > nn_predict_test_y[:, 1], 0, 1) # !-- You can modify here --!\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(test_y_df, result_test))\n",
    "\n",
    "print('\\npredicted testing prob:')\n",
    "print(nn_predict_test_y)\n",
    "print('\\npredicted testing labels:')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision, recall, fbeta-score:\n",
      "(0.4511164643750579, 0.46215139442231074, 0.44874161889029257, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(35, 84, 51, 81)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('\\nprecision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, result_test, average='weighted',labels=np.unique(result_test)))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, result_test).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一開始使用的特徵為：\n",
    "*    Open Price\n",
    "*    Close Price\n",
    "*    High Price\n",
    "*    Low Price\n",
    "*    Volume\n",
    "\n",
    "但是發現不管怎麼調整model或是其餘參數，始終無法提升準確度，一直停留在百分之50上下，我認為這可能並不是模型的問題，而是Data選得不好，Garbage in Garbage out，因此我後來試著調整輸入參數。\n",
    "調整為高低價、高低價差、開盤收盤價差與成交量，但是結果並沒有任何提升。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
