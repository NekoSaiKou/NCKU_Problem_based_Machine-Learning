{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "作業檔案：\n",
    "- hw3.ipynb\n",
    "\n",
    "資料：\n",
    "https://www.sharecast.com/index/SP_500/prices/download\n",
    "\n",
    "- train.csv: S&P 500 訓練資料(2009-2017)\n",
    "- test.csv: S&P 500 測試資料(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "drop_col_names = ['Date'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with the previous days as the training target\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price        Volume  Tomorrow Movement  High Price Diff  \\\n",
      "0      902.99       931.80  4.048270e+09                0.0             1.90   \n",
      "1      929.17       927.45  5.413910e+09                1.0             7.22   \n",
      "2      931.17       934.70  5.392620e+09                0.0           -16.40   \n",
      "3      927.45       906.65  4.704940e+09                1.0           -17.45   \n",
      "4      905.73       909.73  4.991550e+09                0.0             1.93   \n",
      "\n",
      "   Low Price Diff  High Low Diff  \n",
      "0           20.18          35.38  \n",
      "1            7.75          17.10  \n",
      "2          -24.91          16.57  \n",
      "3           -5.56          25.08  \n",
      "4           -8.50          13.19  \n",
      "   Open Price  Close Price        Volume  Tomorrow Movement  High Price Diff  \\\n",
      "0     2683.73      2695.81  1.846463e+09                1.0            18.48   \n",
      "1     2697.85      2713.06  2.090595e+09                1.0            14.92   \n",
      "2     2719.31      2723.99  2.100768e+09                1.0            14.16   \n",
      "3     2731.33      2743.15  1.918869e+09                1.0             5.06   \n",
      "4     2742.67      2747.71  1.894824e+09                1.0            10.63   \n",
      "\n",
      "   Low Price Diff  High Low Diff  \n",
      "0           15.41          13.53  \n",
      "1           21.30          16.60  \n",
      "2            8.85          10.22  \n",
      "3            9.68          15.53  \n",
      "4           10.26          10.91  \n"
     ]
    }
   ],
   "source": [
    "# !--- You can add your own data preprocessing here ---!\n",
    "train_df['High Price Diff'] = train_df['High Price'].diff() \n",
    "test_df['High Price Diff'] = test_df['High Price'].diff()\n",
    "train_df['High Price Diff'] = train_df['High Price Diff'].shift(-1)\n",
    "test_df['High Price Diff'] = test_df['High Price Diff'].shift(-1)\n",
    "\n",
    "train_df['Low Price Diff'] = train_df['Low Price'].diff() \n",
    "test_df['Low Price Diff'] = test_df['Low Price'].diff()\n",
    "train_df['Low Price Diff'] = train_df['Low Price Diff'].shift(-1)\n",
    "test_df['Low Price Diff'] = test_df['Low Price Diff'].shift(-1)\n",
    "\n",
    "train_df['High Low Diff'] = train_df['High Price'] - train_df['Low Price']\n",
    "test_df['High Low Diff'] = test_df['High Price'] - test_df['Low Price']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_col_names = ['High Price','Low Price'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "# Convert np.int64 datatype into np.float64 type for later use\n",
    "train_df = train_df.astype(np.float64)\n",
    "test_df = test_df.astype(np.float64)\n",
    "\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Movement</th>\n",
       "      <th>High Price Diff</th>\n",
       "      <th>Low Price Diff</th>\n",
       "      <th>High Low Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>4.048270e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>20.18</td>\n",
       "      <td>35.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>5.413910e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.75</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>5.392620e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.40</td>\n",
       "      <td>-24.91</td>\n",
       "      <td>16.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>4.704940e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-17.45</td>\n",
       "      <td>-5.56</td>\n",
       "      <td>25.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>4.991550e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>-8.50</td>\n",
       "      <td>13.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Price  Close Price        Volume  Tomorrow Movement  High Price Diff  \\\n",
       "0      902.99       931.80  4.048270e+09                0.0             1.90   \n",
       "1      929.17       927.45  5.413910e+09                1.0             7.22   \n",
       "2      931.17       934.70  5.392620e+09                0.0           -16.40   \n",
       "3      927.45       906.65  4.704940e+09                1.0           -17.45   \n",
       "4      905.73       909.73  4.991550e+09                0.0             1.93   \n",
       "\n",
       "   Low Price Diff  High Low Diff  \n",
       "0           20.18          35.38  \n",
       "1            7.75          17.10  \n",
       "2          -24.91          16.57  \n",
       "3           -5.56          25.08  \n",
       "4           -8.50          13.19  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Movement</th>\n",
       "      <th>High Price Diff</th>\n",
       "      <th>Low Price Diff</th>\n",
       "      <th>High Low Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2684.22</td>\n",
       "      <td>2683.34</td>\n",
       "      <td>1.383889e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>2679.09</td>\n",
       "      <td>2680.50</td>\n",
       "      <td>1.103808e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2682.10</td>\n",
       "      <td>2682.62</td>\n",
       "      <td>1.149108e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>3.78</td>\n",
       "      <td>6.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>2686.10</td>\n",
       "      <td>2687.54</td>\n",
       "      <td>1.126090e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>-9.08</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>2689.15</td>\n",
       "      <td>2673.61</td>\n",
       "      <td>1.332374e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open Price  Close Price        Volume  Tomorrow Movement  \\\n",
       "2259     2684.22      2683.34  1.383889e+09                0.0   \n",
       "2260     2679.09      2680.50  1.103808e+09                1.0   \n",
       "2261     2682.10      2682.62  1.149108e+09                1.0   \n",
       "2262     2686.10      2687.54  1.126090e+09                0.0   \n",
       "2263     2689.15      2673.61  1.332374e+09                NaN   \n",
       "\n",
       "      High Price Diff  Low Price Diff  High Low Diff  \n",
       "2259            -2.61           -0.17           7.22  \n",
       "2260             2.90            0.95           4.78  \n",
       "2261             2.02            3.78           6.73  \n",
       "2262             4.46           -9.08           4.97  \n",
       "2263              NaN             NaN          18.51  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 7)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n",
      "   Open Price  Close Price        Volume  High Price Diff  Low Price Diff  \\\n",
      "0      902.99       931.80  4.048270e+09             1.90           20.18   \n",
      "1      929.17       927.45  5.413910e+09             7.22            7.75   \n",
      "2      931.17       934.70  5.392620e+09           -16.40          -24.91   \n",
      "3      927.45       906.65  4.704940e+09           -17.45           -5.56   \n",
      "4      905.73       909.73  4.991550e+09             1.93           -8.50   \n",
      "\n",
      "   High Low Diff  \n",
      "0          35.38  \n",
      "1          17.10  \n",
      "2          16.57  \n",
      "3          25.08  \n",
      "4          13.19  \n",
      "(2263,)\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(251, 6)\n",
      "   Open Price  Close Price        Volume  High Price Diff  Low Price Diff  \\\n",
      "0     2683.73      2695.81  1.846463e+09            18.48           15.41   \n",
      "1     2697.85      2713.06  2.090595e+09            14.92           21.30   \n",
      "2     2719.31      2723.99  2.100768e+09            14.16            8.85   \n",
      "3     2731.33      2743.15  1.918869e+09             5.06            9.68   \n",
      "4     2742.67      2747.71  1.894824e+09            10.63           10.26   \n",
      "\n",
      "   High Low Diff  \n",
      "0          13.53  \n",
      "1          16.60  \n",
      "2          10.22  \n",
      "3          15.53  \n",
      "4          10.91  \n",
      "(251,)\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "train_x_df = train_df.drop(columns=['Tomorrow Movement'])\n",
    "train_y_df = train_df['Tomorrow Movement']\n",
    "\n",
    "test_x_df = test_df.drop(columns=['Tomorrow Movement'])\n",
    "test_y_df = test_df['Tomorrow Movement']\n",
    "\n",
    "print(train_x_df.shape)\n",
    "print(train_x_df.head())\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())\n",
    "print('-----')\n",
    "print(test_x_df.shape)\n",
    "print(test_x_df.head())\n",
    "print(test_y_df.shape)\n",
    "print(test_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price    Volume  High Price Diff  Low Price Diff  \\\n",
      "0   -1.552572    -1.494607  0.813175         0.100940        1.460319   \n",
      "1   -1.498571    -1.503581  1.823826         0.578946        0.524467   \n",
      "2   -1.494446    -1.488625  1.808070        -1.543326       -1.934499   \n",
      "3   -1.502119    -1.546489  1.299148        -1.637669       -0.477641   \n",
      "4   -1.546921    -1.540136  1.511255         0.103636       -0.698993   \n",
      "\n",
      "   High Low Diff  \n",
      "0       1.859140  \n",
      "1       0.009988  \n",
      "2      -0.043625  \n",
      "3       0.817222  \n",
      "4      -0.385536  \n",
      "------\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "# !--- Modify here if you want ---!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_df)\n",
    "\n",
    "normalized_train_x_df = scaler.transform(train_x_df)\n",
    "normalized_train_x_df = np.transpose(normalized_train_x_df)\n",
    "normalized_train_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_train_x_df[0],\n",
    "    'Close Price': normalized_train_x_df[1],\n",
    "    #'High Price': normalized_train_x_df[2],\n",
    "    #'Low Price': normalized_train_x_df[3],\n",
    "    'Volume': normalized_train_x_df[2],\n",
    "    'High Price Diff': normalized_train_x_df[3],\n",
    "    'Low Price Diff': normalized_train_x_df[4],\n",
    "    'High Low Diff': normalized_train_x_df[5]\n",
    "})\n",
    "\n",
    "normalized_test_x_df = scaler.transform(test_x_df)\n",
    "normalized_test_x_df = np.transpose(normalized_test_x_df)\n",
    "normalized_test_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_test_x_df[0],\n",
    "    'Close Price': normalized_test_x_df[1],\n",
    "    #'High Price': normalized_test_x_df[2],\n",
    "    #'Low Price': normalized_test_x_df[3],\n",
    "    'Volume': normalized_test_x_df[2],\n",
    "    'High Price Diff': normalized_test_x_df[3],\n",
    "    'Low Price Diff': normalized_test_x_df[4],\n",
    "    'High Low Diff': normalized_test_x_df[5]\n",
    "})\n",
    "\n",
    "print(normalized_train_x_df.head())\n",
    "print('------')\n",
    "print(train_y_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if two classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1024 1239]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(train_y_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "\n",
    "#### Solver of sklearn logistic regression\n",
    "Algorithm to use in the optimization problem.\n",
    "\n",
    "*    For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "*    For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss; ‘liblinear’ is limited to one-versus-rest schemes.\n",
    "*    ‘newton-cg’, ‘lbfgs’, ‘sag’ and ‘saga’ handle L2 or no penalty\n",
    "*    ‘liblinear’ and ‘saga’ also handle L1 penalty\n",
    "*    ‘saga’ also supports ‘elasticnet’ penalty\n",
    "*    ‘liblinear’ does not handle no penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.7697746354396818\n",
      "\n",
      "testing accuracy:\n",
      "0.8127490039840638\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict using Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression(solver='liblinear') # !--- Initialize the model here ---!\n",
    "lr_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "lr_training_acc = lr_model.score(normalized_train_x_df, train_y_df)\n",
    "print(lr_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "lr_predict_test_result = lr_model.predict(normalized_test_x_df)\n",
    "lr_testing_acc = np.mean(lr_predict_test_result == test_y_df)\n",
    "print(lr_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.8131861045028519, 0.8127490039840638, 0.8123302384780458, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(92, 27, 20, 112)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, lr_predict_test_result, average='weighted',labels=np.unique( lr_predict_test_result)))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, lr_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.7711003093239063\n",
      "\n",
      "testing accuracy:\n",
      "0.7928286852589641\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict with SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel = 'rbf',gamma=\"scale\") # !--- Initialize the model here ---!\n",
    "svc_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "svc_training_acc = svc_model.score(normalized_train_x_df, train_y_df)\n",
    "print(svc_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "svc_predict_test_result = svc_model.predict(normalized_test_x_df)\n",
    "svc_testing_acc = np.mean(svc_predict_test_result == test_y_df)\n",
    "print(svc_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(svc_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.79470282446541, 0.7928286852589641, 0.7929602727302173, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(97, 22, 30, 102)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, svc_predict_test_result, average='weighted',labels=np.unique(svc_predict_test_result)))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, svc_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of data y indicate if it belongs to class '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 2)\n",
      "   0    1\n",
      "0  1  0.0\n",
      "1  0  1.0\n",
      "2  1  0.0\n",
      "3  0  1.0\n",
      "4  1  0.0\n"
     ]
    }
   ],
   "source": [
    "# Define NN output groundtruth\n",
    "falling_prob = pd.DataFrame(data=np.where(train_y_df == 0, 1, 0)[:])\n",
    "train_y_df_NN = pd.DataFrame(data=np.where(train_y_df == 0, 0, 1)[:],dtype = 'float64')\n",
    "train_y_df_NN = pd.concat( [ falling_prob, train_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(test_y_df == 0, 1, 0)[:])\n",
    "test_y_df_NN = pd.DataFrame(data=np.where(test_y_df == 0, 0, 1)[:],dtype = 'float64')\n",
    "test_y_df_NN = pd.concat( [ falling_prob, test_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "print(train_y_df_NN.shape)\n",
    "print(train_y_df_NN.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - loss:0.6963594556\n",
      "epoch:10 - loss:0.6904361844\n",
      "epoch:20 - loss:0.6840453148\n",
      "epoch:30 - loss:0.6751993895\n",
      "epoch:40 - loss:0.6674014330\n",
      "epoch:50 - loss:0.6604104638\n",
      "epoch:60 - loss:0.6541203260\n",
      "epoch:70 - loss:0.6484080553\n",
      "epoch:80 - loss:0.6432894468\n",
      "epoch:90 - loss:0.6386342049\n",
      "epoch:100 - loss:0.6344174743\n",
      "epoch:110 - loss:0.6305757761\n",
      "epoch:120 - loss:0.6273667216\n",
      "epoch:130 - loss:0.6246622801\n",
      "epoch:140 - loss:0.6223362088\n",
      "epoch:150 - loss:0.6199662089\n",
      "epoch:160 - loss:0.6179315448\n",
      "epoch:170 - loss:0.6162286997\n",
      "epoch:180 - loss:0.6147955656\n",
      "epoch:190 - loss:0.6135820150\n",
      "epoch:200 - loss:0.6122007370\n",
      "epoch:210 - loss:0.6107154489\n",
      "epoch:220 - loss:0.6093586683\n",
      "epoch:230 - loss:0.6079683304\n",
      "epoch:240 - loss:0.6067773104\n",
      "epoch:250 - loss:0.6057904363\n",
      "epoch:260 - loss:0.6050626636\n",
      "epoch:270 - loss:0.6043738127\n",
      "epoch:280 - loss:0.6036623120\n",
      "epoch:290 - loss:0.6029586792\n",
      "epoch:300 - loss:0.6022766829\n",
      "epoch:310 - loss:0.6015803218\n",
      "epoch:320 - loss:0.6009731889\n",
      "epoch:330 - loss:0.6003961563\n",
      "epoch:340 - loss:0.5997892618\n",
      "epoch:350 - loss:0.5991151929\n",
      "epoch:360 - loss:0.5983194113\n",
      "epoch:370 - loss:0.5975649953\n",
      "epoch:380 - loss:0.5968087316\n",
      "epoch:390 - loss:0.5961008072\n",
      "epoch:400 - loss:0.5954660773\n",
      "epoch:410 - loss:0.5947594643\n",
      "epoch:420 - loss:0.5940722227\n",
      "epoch:430 - loss:0.5936235189\n",
      "epoch:440 - loss:0.5932059288\n",
      "epoch:450 - loss:0.5929173231\n",
      "epoch:460 - loss:0.5926338434\n",
      "epoch:470 - loss:0.5923391581\n",
      "epoch:480 - loss:0.5920931697\n",
      "epoch:490 - loss:0.5917787552\n",
      "epoch:500 - loss:0.5916249156\n",
      "epoch:510 - loss:0.5915394425\n",
      "epoch:520 - loss:0.5914640427\n",
      "epoch:530 - loss:0.5914086103\n",
      "epoch:540 - loss:0.5911907554\n",
      "epoch:550 - loss:0.5909814835\n",
      "epoch:560 - loss:0.5907564163\n",
      "epoch:570 - loss:0.5905274749\n",
      "epoch:580 - loss:0.5903514624\n",
      "epoch:590 - loss:0.5901222229\n",
      "epoch:600 - loss:0.5900381804\n",
      "epoch:610 - loss:0.5899170041\n",
      "epoch:620 - loss:0.5897674561\n",
      "epoch:630 - loss:0.5895625353\n",
      "epoch:640 - loss:0.5894135833\n",
      "epoch:650 - loss:0.5893321037\n",
      "epoch:660 - loss:0.5893586278\n",
      "epoch:670 - loss:0.5893518925\n",
      "epoch:680 - loss:0.5892496705\n",
      "epoch:690 - loss:0.5890116692\n",
      "epoch:700 - loss:0.5888658166\n",
      "epoch:710 - loss:0.5887287855\n",
      "epoch:720 - loss:0.5885447264\n",
      "epoch:730 - loss:0.5883216262\n",
      "epoch:740 - loss:0.5881780982\n",
      "epoch:750 - loss:0.5880923867\n",
      "epoch:760 - loss:0.5881793499\n",
      "epoch:770 - loss:0.5881963372\n",
      "epoch:780 - loss:0.5881826282\n",
      "epoch:790 - loss:0.5881996751\n",
      "epoch:800 - loss:0.5882904530\n",
      "epoch:810 - loss:0.5882789493\n",
      "epoch:820 - loss:0.5882624388\n",
      "epoch:830 - loss:0.5882146955\n",
      "epoch:840 - loss:0.5881419778\n",
      "epoch:850 - loss:0.5881546736\n",
      "epoch:860 - loss:0.5881660581\n",
      "epoch:870 - loss:0.5881938934\n",
      "epoch:880 - loss:0.5882348418\n",
      "epoch:890 - loss:0.5884233713\n",
      "epoch:900 - loss:0.5884827375\n",
      "epoch:910 - loss:0.5886009336\n",
      "epoch:920 - loss:0.5886476040\n",
      "epoch:930 - loss:0.5886009932\n",
      "epoch:940 - loss:0.5885581374\n",
      "epoch:950 - loss:0.5885837674\n",
      "epoch:960 - loss:0.5886380076\n",
      "epoch:970 - loss:0.5886694789\n",
      "epoch:980 - loss:0.5886090994\n",
      "epoch:990 - loss:0.5885182619\n"
     ]
    }
   ],
   "source": [
    "# Define NN structure\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !--- You can modify the NN structure here ---!\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        self.linear3 = torch.nn.Linear(H, H)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input layer\n",
    "        i = self.linear1(x)\n",
    "        act_out = F.relu(i)\n",
    "        # Hidden layer\n",
    "        h = self.linear3(act_out)\n",
    "        act2_out = F.relu(h)\n",
    "        # Output layer\n",
    "        o = self.linear2(act2_out)\n",
    "        y_pred = F.relu(o)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "# N = batch size, D_in = input size, H = hidden size, D_out = output size\n",
    "N, D_in, H, D_out = 80, 6, 100, 2  # !--- You can modify here ---!\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean') # !--- You can modify here ---!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3e-3) # !--- You can modify here ---!\n",
    "\n",
    "# Train NN\n",
    "# !--- You can modify here ---!\n",
    "\n",
    "for t in range(1000):\n",
    "    for batch_num in range(N, len(normalized_train_x_df), N): \n",
    "        data = torch.tensor(normalized_train_x_df.iloc[batch_num-N:batch_num].values) # !-- Transfer data into tensor form --!\n",
    "        y_pred = model(data.float()) # !-- Fill the training batch data here --!\n",
    "        target = torch.tensor(train_y_df_NN.iloc[batch_num-N:batch_num].values) # !-- Transfer target into tensor form --!\n",
    "        loss = criterion(y_pred,target.float()) # !-- Fill the prediction & groundtruth here to calculate loss --!\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%10 == 0):\n",
    "        print('epoch:%d - loss:%.10f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.7719840919133893\n",
      "\n",
      "testing accuracy:\n",
      "0.8247011952191236\n",
      "\n",
      "predicted testing prob:\n",
      "tensor([[0.0000, 4.0693],\n",
      "        [0.0000, 3.5868],\n",
      "        [0.0000, 3.2382],\n",
      "        [0.0000, 1.3742],\n",
      "        [0.0000, 2.7084],\n",
      "        [1.9907, 0.0000],\n",
      "        [0.0000, 3.7735],\n",
      "        [0.0000, 4.2739],\n",
      "        [0.0000, 2.5021],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 1.1563],\n",
      "        [0.0000, 4.3613],\n",
      "        [0.0000, 2.0007],\n",
      "        [0.0000, 1.0306],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 4.4253],\n",
      "        [0.0000, 0.0000],\n",
      "        [4.3457, 0.0000],\n",
      "        [0.3047, 0.0000],\n",
      "        [0.1950, 0.0000],\n",
      "        [5.0921, 0.0000],\n",
      "        [9.0213, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.5874],\n",
      "        [7.5139, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 1.2931],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 3.8969],\n",
      "        [0.0000, 2.9510],\n",
      "        [0.0000, 2.9843],\n",
      "        [1.6697, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 1.8188],\n",
      "        [0.0000, 5.1267],\n",
      "        [0.2127, 0.0000],\n",
      "        [1.7196, 0.0000],\n",
      "        [3.2624, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 3.1096],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.9799, 0.0000],\n",
      "        [0.0000, 1.5801],\n",
      "        [0.0000, 7.8336],\n",
      "        [0.0000, 1.4270],\n",
      "        [1.4918, 0.0000],\n",
      "        [0.5690, 0.0000],\n",
      "        [0.3832, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [5.7243, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 2.1375],\n",
      "        [6.6335, 0.0000],\n",
      "        [3.1889, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 2.5973],\n",
      "        [3.0266, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 1.5800],\n",
      "        [0.0000, 1.2270],\n",
      "        [5.6322, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.6844],\n",
      "        [0.0264, 0.0000],\n",
      "        [0.0000, 2.3518],\n",
      "        [0.4538, 0.0000],\n",
      "        [0.0000, 0.3059],\n",
      "        [0.0000, 5.0118],\n",
      "        [0.0000, 0.8441],\n",
      "        [3.1276, 0.0000],\n",
      "        [2.2154, 0.0000],\n",
      "        [0.2057, 0.0000],\n",
      "        [3.0138, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 4.7934],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5920, 0.0000],\n",
      "        [1.9713, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [3.4006, 0.0000],\n",
      "        [0.0000, 3.4391],\n",
      "        [0.0000, 0.7830],\n",
      "        [1.4436, 0.0000],\n",
      "        [0.0000, 4.3800],\n",
      "        [0.0000, 4.3456],\n",
      "        [0.0000, 1.3031],\n",
      "        [0.0000, 1.8821],\n",
      "        [3.5815, 0.0000],\n",
      "        [0.0000, 1.9843],\n",
      "        [0.0000, 0.2414],\n",
      "        [1.0705, 0.0000],\n",
      "        [0.0000, 4.5991],\n",
      "        [0.1390, 0.0000],\n",
      "        [1.5704, 0.0000],\n",
      "        [0.4603, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [4.6362, 0.0000],\n",
      "        [0.0000, 2.6990],\n",
      "        [0.5587, 0.0000],\n",
      "        [0.0000, 2.9481],\n",
      "        [0.0000, 3.0350],\n",
      "        [0.0000, 0.5984],\n",
      "        [0.0000, 3.8339],\n",
      "        [0.0000, 1.1832],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 2.7054],\n",
      "        [0.1852, 0.0000],\n",
      "        [0.2147, 0.0000],\n",
      "        [0.1131, 0.0000],\n",
      "        [1.9734, 0.0000],\n",
      "        [0.6631, 0.0000],\n",
      "        [1.9161, 0.0000],\n",
      "        [0.0000, 2.2913],\n",
      "        [2.4695, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [5.8314, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.4217, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 2.8793],\n",
      "        [2.0278, 0.0000],\n",
      "        [0.0000, 0.9698],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 4.3807],\n",
      "        [0.0000, 3.4951],\n",
      "        [0.0000, 2.7601],\n",
      "        [2.6233, 0.0000],\n",
      "        [0.0000, 2.7759],\n",
      "        [0.0000, 1.2502],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 1.1791],\n",
      "        [0.0000, 0.5601],\n",
      "        [1.0323, 0.0000],\n",
      "        [0.1323, 0.0000],\n",
      "        [0.5130, 0.0000],\n",
      "        [0.0000, 4.4551],\n",
      "        [0.0000, 2.8810],\n",
      "        [0.0000, 0.0000],\n",
      "        [2.8794, 0.0000],\n",
      "        [0.8543, 0.0000],\n",
      "        [0.0000, 0.3585],\n",
      "        [0.0621, 0.0000],\n",
      "        [0.4967, 0.0000],\n",
      "        [0.0000, 1.7506],\n",
      "        [0.0000, 2.7127],\n",
      "        [0.0000, 2.6591],\n",
      "        [0.3849, 0.0000],\n",
      "        [0.1353, 0.0000],\n",
      "        [4.0575, 0.0000],\n",
      "        [0.4709, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [3.1485, 0.0000],\n",
      "        [0.0000, 4.1729],\n",
      "        [0.0000, 0.4382],\n",
      "        [0.0000, 1.1238],\n",
      "        [0.0000, 3.2473],\n",
      "        [1.0323, 0.0000],\n",
      "        [0.1202, 0.0000],\n",
      "        [0.0000, 1.6126],\n",
      "        [0.0000, 4.8425],\n",
      "        [0.0000, 1.5126],\n",
      "        [0.0000, 2.4551],\n",
      "        [0.7143, 0.0000],\n",
      "        [0.8859, 0.0000],\n",
      "        [1.1875, 0.0000],\n",
      "        [1.2813, 0.0000],\n",
      "        [0.9809, 0.0000],\n",
      "        [0.8133, 0.0000],\n",
      "        [0.0000, 0.8500],\n",
      "        [0.3759, 0.0000],\n",
      "        [0.0000, 0.1727],\n",
      "        [0.0000, 2.9939],\n",
      "        [0.0000, 0.3393],\n",
      "        [1.2721, 0.0000],\n",
      "        [0.0000, 0.8481],\n",
      "        [0.0000, 0.5642],\n",
      "        [0.0000, 4.9830],\n",
      "        [0.0000, 1.4017],\n",
      "        [2.0410, 0.0000],\n",
      "        [0.0000, 0.3149],\n",
      "        [0.2417, 0.0960],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.7789, 0.0000],\n",
      "        [0.0000, 3.4076],\n",
      "        [0.4533, 0.0000],\n",
      "        [0.0000, 1.5114],\n",
      "        [4.1241, 0.0000],\n",
      "        [0.7996, 0.0000],\n",
      "        [0.3461, 0.0000],\n",
      "        [0.0000, 0.5198],\n",
      "        [7.8827, 0.0000],\n",
      "        [3.2833, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 5.1920],\n",
      "        [0.0000, 0.0000],\n",
      "        [1.6509, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.5766, 0.0000],\n",
      "        [4.9884, 0.0000],\n",
      "        [0.4302, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [1.5357, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 7.4574],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0429],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 2.1756],\n",
      "        [0.0000, 9.5927],\n",
      "        [0.0000, 0.0000],\n",
      "        [3.5803, 0.0000],\n",
      "        [3.3892, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [1.2687, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 0.0405],\n",
      "        [1.9873, 0.0000],\n",
      "        [4.0294, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [2.8157, 0.0000],\n",
      "        [0.0000, 4.9806],\n",
      "        [0.0000, 0.8676],\n",
      "        [0.0000, 8.8168],\n",
      "        [0.0000, 0.0435],\n",
      "        [0.0000, 0.3275],\n",
      "        [0.0000, 6.6511],\n",
      "        [6.0185, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [3.9611, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.3253, 0.0000],\n",
      "        [0.0000, 1.4656],\n",
      "        [0.0000, 0.2175],\n",
      "        [0.7280, 0.0000],\n",
      "        [4.0821, 0.0000],\n",
      "        [4.7730, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [1.0936, 0.0000],\n",
      "        [0.4274, 0.0000],\n",
      "        [0.0000, 0.0000],\n",
      "        [1.8423, 0.0000],\n",
      "        [0.0000, 3.0679],\n",
      "        [0.0000, 0.0000],\n",
      "        [0.0000, 1.1175],\n",
      "        [0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "predicted testing labels:\n",
      "[1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0\n",
      " 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1\n",
      " 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 1 1 1 1 0 1 0\n",
      " 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "x_train = torch.tensor(normalized_train_x_df.values).float()\n",
    "nn_predict_train_y = model(x_train) # !-- Predict training data here --!\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 0, 1) # !-- You can modify here --!\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(train_y_df, result_train))\n",
    "\n",
    "x_test = torch.tensor(normalized_test_x_df.values).float()\n",
    "nn_predict_test_y = model(x_test) # !-- Predict training data here --!\n",
    "result_test = np.where(nn_predict_test_y[:, 0] > nn_predict_test_y[:, 1], 0, 1) # !-- You can modify here --!\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(test_y_df, result_test))\n",
    "\n",
    "print('\\npredicted testing prob:')\n",
    "print(nn_predict_test_y)\n",
    "print('\\npredicted testing labels:')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision, recall, fbeta-score:\n",
      "(0.47410358565737054, 1.0, 0.6432432432432432, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(119, 0, 132, 0)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('\\nprecision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, result_test, average='weighted',labels=np.unique(result_test)))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, result_test).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將High price、Low price移除掉並換成其與下一筆資料的差值以後，並且加上高低價的價差，訓練出的結果得到了顯著的提升。\n",
    "神經網路的架構上，包含了一個輸入層、一個中間層與一個輸出層，三個的激勵函數都使用ReLU，最後在經過sigmoid得到結果。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
